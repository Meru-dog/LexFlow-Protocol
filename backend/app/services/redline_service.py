"""
LexFlow Protocol - Redline Service
å¥‘ç´„æ›¸ã®å·®åˆ†è§£æã¨AIãƒªã‚¹ã‚¯è©•ä¾¡ã‚’å®Ÿè¡Œã™ã‚‹ã‚µãƒ¼ãƒ“ã‚¹
"""
from typing import List, Optional, Dict, Any
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
import difflib
import json
import os
import re

from app.core.config import settings
from app.services.contract_parser import contract_parser


class ChangeItem(BaseModel):
    """å€‹ã€…ã®å¤‰æ›´ç®‡æ‰€ã‚’è¡¨ã™ãƒ¢ãƒ‡ãƒ«"""
    change_type: str = Field(description="å¤‰æ›´ã‚¿ã‚¤ãƒ—: add, delete, modify")
    location: str = Field(description="å¤‰æ›´ç®‡æ‰€ã®ä½ç½®æƒ…å ±")
    old_text: Optional[str] = Field(default=None, description="å¤‰æ›´å‰ã®ãƒ†ã‚­ã‚¹ãƒˆ")
    new_text: Optional[str] = Field(default=None, description="å¤‰æ›´å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ")
    risk_level: str = Field(default="low", description="ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: high, medium, low")
    risk_reason: Optional[str] = Field(default=None, description="ãƒªã‚¹ã‚¯åˆ¤å®šã®ç†ç”±")
    recommendation: Optional[str] = Field(default=None, description="AIã‹ã‚‰ã®ææ¡ˆ")


class RiskAssessment(BaseModel):
    """ãƒªã‚¹ã‚¯è©•ä¾¡ã®å…¨ä½“ã‚µãƒãƒªãƒ¼"""
    high_risk_count: int = Field(default=0, description="é«˜ãƒªã‚¹ã‚¯å¤‰æ›´ã®ä»¶æ•°")
    medium_risk_count: int = Field(default=0, description="ä¸­ãƒªã‚¹ã‚¯å¤‰æ›´ã®ä»¶æ•°")
    low_risk_count: int = Field(default=0, description="ä½ãƒªã‚¹ã‚¯å¤‰æ›´ã®ä»¶æ•°")
    overall_risk: str = Field(default="low", description="å…¨ä½“ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: high, medium, low")
    summary: str = Field(default="", description="ãƒªã‚¹ã‚¯è©•ä¾¡ã®ã‚µãƒãƒªãƒ¼")


class RedlineResult(BaseModel):
    """å·®åˆ†è§£æã®å…¨ä½“çµæœ"""
    old_version_id: str
    new_version_id: str
    changes: List[ChangeItem] = Field(default=[])
    summary: str = Field(default="", description="AIç”Ÿæˆã®å¤‰æ›´è¦ç´„")
    risk_assessment: RiskAssessment = Field(default_factory=RiskAssessment)
    recommendations: List[str] = Field(default=[], description="AIã‹ã‚‰ã®å…¨ä½“çš„ãªææ¡ˆ")
    diff_html: str = Field(default="", description="HTMLå½¢å¼ã®å·®åˆ†è¡¨ç¤º")


class RedlineService:
    """
    å¥‘ç´„æ›¸ã®å·®åˆ†è§£æã¨AIãƒªã‚¹ã‚¯è©•ä¾¡ã‚’è¡Œã†ã‚µãƒ¼ãƒ“ã‚¹
    """
    
    def __init__(self):
        """ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–"""
        self.llm = ChatOpenAI(
            model="gpt-4-turbo-preview",
            temperature=0,
            api_key=settings.OPENAI_API_KEY,
        )
    
    def compute_text_diff(self, old_text: str, new_text: str) -> List[Dict[str, Any]]:
        """
        2ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆé–“ã®å·®åˆ†ã‚’è¨ˆç®—ã—ã€ãƒ–ãƒ­ãƒƒã‚¯å˜ä½ã§ã¾ã¨ã‚ã‚‹
        """
        old_lines = old_text.splitlines()
        new_lines = new_text.splitlines()
        
        matcher = difflib.SequenceMatcher(None, old_lines, new_lines)
        blocks = []
        
        for tag, i1, i2, j1, j2 in matcher.get_opcodes():
            if tag == 'equal':
                continue
                
            block = {
                'type': tag, # 'replace', 'delete', 'insert'
                'old_text': "\n".join(old_lines[i1:i2]) if tag in ['replace', 'delete'] else None,
                'new_text': "\n".join(new_lines[j1:j2]) if tag in ['replace', 'insert'] else None,
                'location': f"L{i1+1}-{i2}" if i1 != i2 else f"L{j1+1}-{j2}"
            }
            blocks.append(block)
        
        return blocks
    
    def generate_diff_html(self, old_text: str, new_text: str) -> str:
        """
        HTMLå½¢å¼ã®å·®åˆ†è¡¨ç¤ºã‚’ç”Ÿæˆã—ã€ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‚«ãƒ¼ã‚’ç•ªå·ãƒãƒƒã‚¸ã«ç½®ãæ›ãˆã‚‹
        """
        differ = difflib.HtmlDiff(wrapcolumn=80)
        html = differ.make_table(
            old_text.splitlines(),
            new_text.splitlines(),
            fromdesc='æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³',
            todesc='æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³',
            context=True,
            numlines=3
        )
        
        # <tr>å˜ä½ã§åˆ†å‰²ã—ã¦å‡¦ç†
        rows = re.findall(r'<tr.*?>.*?</tr>', html, re.DOTALL)
        count = 1
        processed_rows = []
        
        for row in rows:
            # å¤‰æ›´ãŒå«ã¾ã‚Œã‚‹è¡Œï¼ˆdiff_add, diff_sub, diff_chgï¼‰ã‹ã©ã†ã‹ã‚’ç¢ºèª
            is_change_row = 'class="diff_add"' in row or 'class="diff_sub"' in row or 'class="diff_chg"' in row
            
            # ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒªãƒ³ã‚¯ (f, n, p, t) ã‚’æ¢ã™
            if is_change_row and re.search(r'>(f|n|p|t)</a>', row):
                # å¤‰æ›´è¡Œã®ãƒãƒ¼ã‚«ãƒ¼ã‚’ç•ªå·ä»˜ããƒãƒƒã‚¸ã«ç½®æ›
                badge_html = f'><span style="background-color: #4f46e5; color: white; border-radius: 50%; width: 18px; height: 18px; display: inline-flex; align-items: center; justify-content: center; font-size: 10px; font-weight: bold; margin: 0 2px;">{count}</span></a>'
                row = re.sub(r'>(f|n|p|t)</a>', badge_html, row)
                count += 1
            elif re.search(r'>(f|n|p|t)</a>', row):
                # å¤‰æ›´ã§ã¯ãªã„è¡Œã«ã‚ã‚‹ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ãƒãƒ¼ã‚«ãƒ¼ï¼ˆå…ˆé ­ã‚¸ãƒ£ãƒ³ãƒ—ãªã©ï¼‰ã¯éè¡¨ç¤ºã«ã™ã‚‹
                row = re.sub(r'>(f|n|p|t)</a>', '></a>', row)
                
            processed_rows.append(row)
            
        # å†æ§‹ç¯‰ï¼ˆtheadã‚„colgroupãªã©ã¯ç¶­æŒã—ã€tbodyã®ä¸­èº«ã‚’å·®ã—æ›¿ãˆï¼‰
        # é¢å€’ãªã®ã§å…¨ç½®æ›ã•ã‚ŒãŸè¡Œãƒªã‚¹ãƒˆã§å†çµåˆã™ã‚‹ãŒã€make_tableã®è¿”ã‚Šå€¤å…¨ä½“ã«å¯¾ã—ã¦è¡Œã†
        # findallã§å–å¾—ã—ãŸå…¨trã‚’é †ç•ªã«ç½®æ›ã—ã¦ã„ã
        result_html = html
        for original, processed in zip(rows, processed_rows):
            if original != processed:
                result_html = result_html.replace(original, processed, 1)
                
        return result_html
    
    async def analyze_changes_with_ai(
        self, 
        old_text: str, 
        new_text: str,
        changes: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        å¤‰æ›´ç®‡æ‰€ã‚’AIã§è§£æã—ã€ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’è¡Œã†
        
        Args:
            old_text: æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å…¨æ–‡
            new_text: æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®å…¨æ–‡
            changes: å·®åˆ†æƒ…å ±ã®ãƒªã‚¹ãƒˆ
            
        Returns:
            AIè§£æçµæœï¼ˆãƒªã‚¹ã‚¯è©•ä¾¡ã€ææ¡ˆãªã©ï¼‰
        """
        # å¤‰æ›´å†…å®¹ã‚’æ–‡å­—åˆ—åŒ–
        changes_summary = "\n".join([
            f"- {'å‰Šé™¤' if c['type'] == 'delete' else 'è¿½åŠ '}: {c.get('old_text') or c.get('new_text')}"
            for c in changes[:50]  # æœ€å¤§50ä»¶ã«åˆ¶é™
        ])
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ã‚ãªãŸã¯æ³•å‹™å°‚é–€ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚å¥‘ç´„æ›¸ã®å¤‰æ›´ç‚¹ã‚’åˆ†æã—ã€ãƒªã‚¹ã‚¯è©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚
            
            ä»¥ä¸‹ã®å½¢å¼ã§JSONå½¢å¼ã®å‡ºåŠ›ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
            
            {{
            "summary": "å¤‰æ›´å†…å®¹ã®è¦ç´„ï¼ˆæ—¥æœ¬èªã€2-3æ–‡ï¼‰",
            "changes": [
                {{
                    "index": 1,
                    "description": "å¤‰æ›´å†…å®¹ã®èª¬æ˜",
                    "change_type": "modify/add/delete",
                    "risk_level": "high/medium/low",
                    "risk_reason": "ãƒªã‚¹ã‚¯åˆ¤å®šã®ç†ç”±",
                    "recommendation": "å¯¾å¿œã®ææ¡ˆ"
                }}
            ],
            "overall_risk": "high/medium/low",
            "overall_summary": "å…¨ä½“çš„ãªãƒªã‚¹ã‚¯è©•ä¾¡ã®ã‚µãƒãƒªãƒ¼",
            "recommendations": ["ææ¡ˆ1", "ææ¡ˆ2"]
            }}

            ãƒªã‚¹ã‚¯åˆ¤å®šåŸºæº–ï¼š
            - highï¼ˆé«˜ï¼‰: æ”¯æ‰•æ¡ä»¶ã€è²¬ä»»åˆ¶é™ã€å¥‘ç´„è§£é™¤ã€æå®³è³ å„Ÿã«é–¢ã™ã‚‹é‡å¤§ãªå¤‰æ›´
            - mediumï¼ˆä¸­ï¼‰: æœŸé™ã€é€šçŸ¥ç¾©å‹™ã€ç§˜å¯†ä¿æŒã«é–¢ã™ã‚‹å¤‰æ›´
            - lowï¼ˆä½ï¼‰: è»½å¾®ãªæ–‡è¨€ä¿®æ­£ã€å½¢å¼çš„ãªå¤‰æ›´"""),
            ("human", """ä»¥ä¸‹ã®å¥‘ç´„æ›¸ã®å¤‰æ›´ç‚¹ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚
            
            ã€å¤‰æ›´ç®‡æ‰€ä¸€è¦§ã€‘
            {changes}
            
            ã€æ—§ãƒãƒ¼ã‚¸ãƒ§ãƒ³å…¨æ–‡ï¼ˆæŠœç²‹ï¼‰ã€‘
            {old_text}

            ã€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³å…¨æ–‡ï¼ˆæŠœç²‹ï¼‰ã€‘
            {new_text}

            ä¸Šè¨˜ã®å¤‰æ›´ã«ã¤ã„ã¦ã€æ³•å‹™è¦³ç‚¹ã‹ã‚‰ã®ãƒªã‚¹ã‚¯è©•ä¾¡ã¨ææ¡ˆã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚""")
        ])
        
        formatted_prompt = prompt.format_messages(
            changes=changes_summary,
            old_text=old_text[:5000],  # æ–‡å­—æ•°åˆ¶é™
            new_text=new_text[:5000]
        )
        
        try:
            response = await self.llm.ainvoke(formatted_prompt)
            content = response.content
            
            # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0]
            elif "```" in content:
                content = content.split("```")[1].split("```")[0]
            
            result = json.loads(content)
            return result
            
        except Exception as e:
            print(f"âŒ AI analysis failed: {e}")
            return {
                "summary": "AIè§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                "changes": [],
                "overall_risk": "medium",
                "overall_summary": "AIè§£æã‚¨ãƒ©ãƒ¼",
                "recommendations": ["æ‰‹å‹•ã§ã®ç¢ºèªã‚’æ¨å¥¨ã—ã¾ã™"]
            }
    
    async def compare_versions(
        self,
        old_file_content: bytes,
        new_file_content: bytes,
        old_version_id: str,
        new_version_id: str,
        old_filename: str = "old_document",
        new_filename: str = "new_document"
    ) -> RedlineResult:
        """
        2ã¤ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ¯”è¼ƒã—ã€å·®åˆ†ã¨AIåˆ†æã‚’è¿”ã™
        """
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        print(f"ğŸ“„ Extracting text from old version ({old_filename})...")
        old_text = await contract_parser.extract_text_from_file(old_file_content, old_filename)
        
        print(f"ğŸ“„ Extracting text from new version ({new_filename})...")
        new_text = await contract_parser.extract_text_from_file(new_file_content, new_filename)
        
        # 2. å·®åˆ†è¨ˆç®—
        print(f"ğŸ” Computing differences...")
        raw_changes = self.compute_text_diff(old_text, new_text)
        
        # 3. HTMLå½¢å¼ã®å·®åˆ†ç”Ÿæˆ
        diff_html = self.generate_diff_html(old_text, new_text)
        
        # 4. AIè§£æ
        print(f"ğŸ¤– Analyzing changes with AI...")
        ai_analysis = await self.analyze_changes_with_ai(old_text, new_text, raw_changes)
        
        # 5. çµæœã®æ§‹ç¯‰
        changes = []
        ai_changes = ai_analysis.get("changes", [])
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«åŸºã¥ã„ã¦æ•´ç†
        for i, ai_change in enumerate(ai_changes):
            idx = ai_change.get("index", i + 1)
            changes.append(ChangeItem(
                change_type=ai_change.get("change_type", "modify"),
                location=f"å¤‰æ›´ç®‡æ‰€ {idx}",
                old_text=None,
                new_text=None,
                risk_level=ai_change.get("risk_level", "low"),
                risk_reason=ai_change.get("risk_reason", ""),
                recommendation=ai_change.get("recommendation", "")
            ))
        
        # ãƒªã‚¹ã‚¯ã‚«ã‚¦ãƒ³ãƒˆ
        high_count = sum(1 for c in changes if c.risk_level == "high")
        medium_count = sum(1 for c in changes if c.risk_level == "medium")
        low_count = sum(1 for c in changes if c.risk_level == "low")
        
        risk_assessment = RiskAssessment(
            high_risk_count=high_count,
            medium_risk_count=medium_count,
            low_risk_count=low_count,
            overall_risk=ai_analysis.get("overall_risk", "low"),
            summary=ai_analysis.get("overall_summary", "")
        )
        
        result = RedlineResult(
            old_version_id=old_version_id,
            new_version_id=new_version_id,
            changes=changes,
            summary=ai_analysis.get("summary", ""),
            risk_assessment=risk_assessment,
            recommendations=ai_analysis.get("recommendations", []),
            diff_html=diff_html
        )
        
        return result


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
redline_service = RedlineService()
