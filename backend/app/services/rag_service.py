"""
LexFlow Protocol - RAG (Retrieval-Augmented Generation) ã‚µãƒ¼ãƒ“ã‚¹
å¥‘ç´„æ›¸ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã€æ¤œç´¢ã€ãŠã‚ˆã³ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’æ‹…å½“
"""
import os
import chromadb
from chromadb.config import Settings
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from typing import List, Dict, Any, Optional

from app.core.config import settings

class RAGService:
    """
    RAGã‚µãƒ¼ãƒ“ã‚¹
    ChromaDBã‚’ä½¿ç”¨ã—ã¦ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã¨æ¤œç´¢ã‚’è¡Œã†
    """
    
    def __init__(self):
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            api_key=settings.OPENAI_API_KEY
        )
        
        # æ°¸ç¶šåŒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®ãƒ‘ã‚¹è¨­å®š
        self.persist_directory = os.path.join(os.getcwd(), "chroma_db")
        os.makedirs(self.persist_directory, exist_ok=True)
        
        # ChromaDB ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        self.client = chromadb.PersistentClient(path=self.persist_directory)
        
        print(f"ğŸ“¦ RAG ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–: {self.persist_directory}")

    def _get_vectorstore(self, workspace_id: str):
        """
        ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã”ã¨ã®ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã‚’å–å¾—
        ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã¯ workspace_id ã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹
        """
        collection_name = f"workspace_{workspace_id.replace('-', '_')}"
        
        return Chroma(
            client=self.client,
            collection_name=collection_name,
            embedding_function=self.embeddings,
            persist_directory=self.persist_directory
        )

    async def index_contract(self, contract_id: str, workspace_id: str, text: str, metadata: Dict[str, Any] = None):
        """
        å¥‘ç´„æ›¸ã‚’ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã—ã¦ãƒ™ã‚¯ãƒˆãƒ«DBã«ç™»éŒ²
        """
        if not text or len(text.strip()) < 10:
            print(f"âš ï¸ {contract_id}: ãƒ†ã‚­ã‚¹ãƒˆãŒçŸ­ã™ãã¾ã™")
            return
            
        print(f"ğŸ” {contract_id}: ãƒ™ã‚¯ãƒˆãƒ«DBã«ç™»éŒ²ä¸­...")
        
        # ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=100,
            length_function=len,
            is_separator_regex=False,
        )
        
        chunks = text_splitter.split_text(text)
        print(f"âœ‚ï¸ {contract_id}: {len(chunks)} ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        final_metadata = {
            "contract_id": contract_id,
            "workspace_id": workspace_id,
        }
        if metadata:
            final_metadata.update(metadata)
            
        # ãƒ™ã‚¯ã‚¿ãƒ¼ã‚¹ãƒˆã‚¢ã®å–å¾—
        vectorstore = self._get_vectorstore(workspace_id)
        
        # æ—¢å­˜ã®å½“è©²ã‚³ãƒ³ãƒˆãƒ©ã‚¯ãƒˆæƒ…å ±ã‚’å‰Šé™¤ï¼ˆå†ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç”¨ï¼‰
        try:
            vectorstore.delete(where={"contract_id": contract_id})
        except Exception:
            pass # æœªç™»éŒ²ã®å ´åˆã¯ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŒç„¡è¦–
            
        # ç™»éŒ²
        vectorstore.add_texts(
            texts=chunks,
            metadatas=[final_metadata] * len(chunks)
        )
        
        print(f"âœ… {contract_id}: ãƒ™ã‚¯ãƒˆãƒ«DBã«ç™»éŒ²ã—ã¾ã—ãŸ")

    async def search_relevant_context(self, workspace_id: str, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """
        ã‚¯ã‚¨ãƒªã«é–¢é€£ã™ã‚‹ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¤œç´¢
        """
        vectorstore = self._get_vectorstore(workspace_id)
        
        results = vectorstore.similarity_search_with_score(query, k=limit)
        
        formatted_results = []
        for doc, score in results:
            formatted_results.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "score": float(score)
            })
            
        return formatted_results

    async def query_with_context(self, workspace_id: str, query: str) -> Dict[str, Any]:
        """
        ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ¤œç´¢ã—ã€ãã‚Œã«åŸºã¥ã„ãŸå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®æº–å‚™
        ï¼ˆå®Ÿéš›ã®LLMå‘¼ã³å‡ºã—ã¯ judgment_service ç­‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§åˆ©ç”¨ã™ã‚‹ã“ã¨ã‚’æƒ³å®šï¼‰
        """
        contexts = await self.search_relevant_context(workspace_id, query)
        combined_context = "\n\n".join([c["content"] for c in contexts])
        
        return {
            "query": query,
            "context": combined_context,
            "source_documents": [c["metadata"].get("contract_id") for c in contexts]
        }

# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
rag_service = RAGService()
